import os
import time
import torch
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torch import nn
from dataset import CatDogDataset  # ç¡®ä¿ dataset.py æ–‡ä»¶å­˜åœ¨ä¸”è·¯å¾„æ­£ç¡®
from model import build_vgg16_model  # ç¡®ä¿ model.py æ–‡ä»¶å­˜åœ¨ä¸”è·¯å¾„æ­£ç¡®


class CatDogTrainer:
    def __init__(self, train_dir, test_dir, transform, skip_train=False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨ã€‚
        å‚æ•°:
            train_dir (str): è®­ç»ƒæ•°æ®ç›®å½•è·¯å¾„ã€‚
            test_dir (str): æµ‹è¯•æ•°æ®ç›®å½•è·¯å¾„ã€‚
            transform (callable): åº”ç”¨äºå›¾åƒçš„é¢„å¤„ç†è½¬æ¢ã€‚
            skip_train (bool): å¦‚æœä¸ºTrueä¸”æ¨¡å‹æƒé‡å­˜åœ¨ï¼Œåˆ™è·³è¿‡è®­ç»ƒã€‚
        """
        self.train_dir = train_dir
        self.test_dir = test_dir
        self.transform = transform
        self.skip_train = skip_train

        self.batch_size = 20  # è®­ç»ƒå’Œæµ‹è¯•æ—¶çš„æ‰¹å¤„ç†å¤§å°
        self.epochs = 10  # è®­ç»ƒçš„æ€»è½®æ•°

        # æ ¹æ®å¯ç”¨æ€§é€‰æ‹©è®¾å¤‡ (GPU æˆ– CPU)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        # æ„å»ºVGG16æ¨¡å‹å¹¶å°†å…¶ç§»åŠ¨åˆ°é€‰å®šçš„è®¾å¤‡
        self.model = build_vgg16_model().to(self.device)
        # å®šä¹‰æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆæƒé‡ï¼‰çš„ä¿å­˜è·¯å¾„
        self.checkpoint_path = "./checkpoints/catdog_vgg16.pth"
        # å®šä¹‰ä¼˜åŒ–å™¨ï¼Œè¿™é‡Œä½¿ç”¨å¸¦åŠ¨é‡çš„éšæœºæ¢¯åº¦ä¸‹é™ (SGD)
        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)
        # å®šä¹‰æŸå¤±å‡½æ•°ï¼Œè¿™é‡Œä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œé€‚ç”¨äºå¤šåˆ†ç±»é—®é¢˜
        self.loss_fn = nn.CrossEntropyLoss()

        # åˆå§‹åŒ–åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªepochçš„è®­ç»ƒæŸå¤±å’Œæµ‹è¯•æŸå¤±ï¼Œä»¥ä¾¿åç»­ç»˜å›¾
        self.train_losses = []
        self.test_losses = []
        # (å¯é€‰) åˆå§‹åŒ–åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªepochçš„è®­ç»ƒå‡†ç¡®ç‡å’Œæµ‹è¯•å‡†ç¡®ç‡
        # self.train_accuracies = []
        # self.test_accuracies = []

    def load_data(self):
        """åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ã€‚"""
        # åˆ›å»ºè®­ç»ƒæ•°æ®é›†å®ä¾‹
        train_dataset = CatDogDataset(self.train_dir, self.transform)
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å®ä¾‹
        test_dataset = CatDogDataset(self.test_dir, self.transform)
        # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œç”¨äºæ‰¹é‡åŠ è½½æ•°æ®ï¼Œå¹¶åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶æ‰“ä¹±é¡ºåº
        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)
        print(f"æ•°æ®åŠ è½½å®Œæ¯•ï¼šè®­ç»ƒé›†å›¾åƒ {len(train_dataset)} å¼ ï¼Œæµ‹è¯•é›†å›¾åƒ {len(test_dataset)} å¼ ã€‚")

    def save_model(self):
        """ä¿å­˜å½“å‰æ¨¡å‹çš„æƒé‡åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶ã€‚"""
        # ç¡®ä¿ä¿å­˜è·¯å¾„çš„ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        os.makedirs(os.path.dirname(self.checkpoint_path), exist_ok=True)
        # ä¿å­˜æ¨¡å‹çš„çŠ¶æ€å­—å…¸ (åŒ…å«æ‰€æœ‰å¯å­¦ä¹ çš„å‚æ•°)
        torch.save(self.model.state_dict(), self.checkpoint_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³ {self.checkpoint_path}")

    def load_model(self):
        """ä»æ£€æŸ¥ç‚¹æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡ã€‚"""
        if os.path.exists(self.checkpoint_path):  # æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            try:
                # åŠ è½½æƒé‡åˆ°æ¨¡å‹ï¼Œmap_locationç¡®ä¿æƒé‡èƒ½æ­£ç¡®åŠ è½½åˆ°å½“å‰è®¾å¤‡
                self.model.load_state_dict(torch.load(self.checkpoint_path, map_location=self.device))
                self.model.eval()  # åŠ è½½åå°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œè¿™ä¼šå…³é—­dropoutç­‰å±‚
                print(f"âœ… å·²åŠ è½½æ¨¡å‹æƒé‡ï¼š{self.checkpoint_path}")
                return True  # è¿”å›Trueè¡¨ç¤ºåŠ è½½æˆåŠŸ
            except Exception as e:
                print(f"âš ï¸ åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥ï¼š{e}ã€‚å°†é‡æ–°è®­ç»ƒã€‚")
                return False  # è¿”å›Falseè¡¨ç¤ºåŠ è½½å¤±è´¥
        else:
            print("â„¹ï¸ æœªæ‰¾åˆ°å·²ä¿å­˜æ¨¡å‹ï¼Œå°†é‡æ–°è®­ç»ƒã€‚")
            return False  # æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè¿”å›False

    def evaluate(self, loader, label="æµ‹è¯•"):
        """
        åœ¨ç»™å®šçš„æ•°æ®åŠ è½½å™¨ä¸Šè¯„ä¼°æ¨¡å‹ã€‚
        å‚æ•°:
            loader (DataLoader): ç”¨äºè¯„ä¼°çš„æ•°æ®åŠ è½½å™¨ (å¯ä»¥æ˜¯è®­ç»ƒæˆ–æµ‹è¯•åŠ è½½å™¨)ã€‚
            label (str): è¯„ä¼°çš„æ ‡ç­¾ (ä¾‹å¦‚ "æµ‹è¯•", "è®­ç»ƒ")ï¼Œç”¨äºæ‰“å°ä¿¡æ¯ã€‚
        è¿”å›:
            tuple: åŒ…å«å¹³å‡æŸå¤± (float) å’Œå‡†ç¡®ç‡ (float) çš„å…ƒç»„ã€‚
        """
        self.model.eval()  # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        correct = 0  # æ­£ç¡®é¢„æµ‹çš„æ•°é‡
        total_loss = 0  # å½“å‰æ•°æ®é›†ä¸Šçš„æ€»æŸå¤±
        dataset_size = len(loader.dataset)  # æ•°æ®é›†æ€»å¤§å°

        with torch.no_grad():  # åœ¨è¯„ä¼°æœŸé—´ä¸è®¡ç®—æ¢¯åº¦ï¼Œä»¥èŠ‚çœå†…å­˜å’Œè®¡ç®—
            for x, y in loader:  # éå†æ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡
                x, y = x.to(self.device), y.to(self.device)  # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
                pred = self.model(x)  # æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœ
                loss = self.loss_fn(pred, y)  # è®¡ç®—æŸå¤±
                total_loss += loss.item() * x.size(0)  # ç´¯åŠ æ‰¹æ¬¡æŸå¤± (ä¹˜ä»¥æ‰¹æ¬¡å¤§å°ä»¥å¾—åˆ°æ‰¹æ¬¡æ€»æŸå¤±)

                pred_labels = torch.argmax(pred, dim=1)  # è·å–é¢„æµ‹æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹æ ‡ç­¾
                correct += (pred_labels == y).sum().item()  # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹çš„æ•°é‡

        avg_loss = total_loss / dataset_size  # è®¡ç®—å¹³å‡æŸå¤±
        acc = correct / dataset_size  # è®¡ç®—å‡†ç¡®ç‡

        print(f"{label}é›†å‡†ç¡®ç‡: {acc * 100:.2f}% | å¹³å‡æŸå¤±: {avg_loss:.4f}")
        return avg_loss, acc  # è¿”å›å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡

    def train(self):
        """æ‰§è¡Œæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚"""
        print(f"å¼€å§‹åœ¨ {self.device} ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…± {self.epochs} ä¸ª epochs...")
        start_time = time.time()  # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´

        for epoch in range(self.epochs):  # éå†æ¯ä¸ªepoch
            self.model.train()  # åœ¨æ¯ä¸ªepochçš„è®­ç»ƒé˜¶æ®µå¼€å§‹æ—¶ï¼Œç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼

            epoch_train_loss_sum = 0.0  # å½“å‰epochçš„è®­ç»ƒæ€»æŸå¤±ç´¯åŠ å™¨
            # epoch_train_correct = 0 # (å¯é€‰) å½“å‰epochçš„è®­ç»ƒæ­£ç¡®æ•°ç´¯åŠ å™¨

            # éå†è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡
            for batch_idx, (x, y) in enumerate(self.train_loader):
                x, y = x.to(self.device), y.to(self.device)  # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡

                # å‰å‘ä¼ æ’­
                pred = self.model(x)
                loss = self.loss_fn(pred, y)

                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                self.optimizer.zero_grad()  # æ¸…é™¤ä¹‹å‰çš„æ¢¯åº¦
                loss.backward()  # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æ¢¯åº¦
                self.optimizer.step()  # æ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°

                epoch_train_loss_sum += loss.item() * x.size(0)  # ç´¯åŠ æ‰¹æ¬¡æŸå¤±
                # pred_labels_train = torch.argmax(pred, dim=1) # (å¯é€‰) è·å–è®­ç»ƒæ‰¹æ¬¡çš„é¢„æµ‹æ ‡ç­¾
                # epoch_train_correct += (pred_labels_train == y).sum().item() # (å¯é€‰) ç´¯åŠ è®­ç»ƒæ‰¹æ¬¡çš„æ­£ç¡®æ•°

                # æ¯å¤„ç†50ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡å½“å‰æ‰¹æ¬¡çš„æŸå¤±ï¼Œæ–¹ä¾¿ç›‘æ§è®­ç»ƒè¿›åº¦
                if batch_idx % 50 == 0:
                    print(
                        f"Epoch {epoch + 1}/{self.epochs} | Batch {batch_idx}/{len(self.train_loader)} | Batch Loss: {loss.item():.4f}")

            # è®¡ç®—å½“å‰epochçš„å¹³å‡è®­ç»ƒæŸå¤±
            avg_epoch_train_loss = epoch_train_loss_sum / len(self.train_loader.dataset)
            self.train_losses.append(avg_epoch_train_loss)  # è®°å½•åˆ°åˆ—è¡¨ä¸­
            # avg_epoch_train_acc = epoch_train_correct / len(self.train_loader.dataset) # (å¯é€‰) è®¡ç®—å¹³å‡è®­ç»ƒå‡†ç¡®ç‡
            # self.train_accuracies.append(avg_epoch_train_acc) # (å¯é€‰) è®°å½•

            # åœ¨æ¯ä¸ªepochè®­ç»ƒå®Œæˆåï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
            # evaluate æ–¹æ³•å†…éƒ¨ä¼šå°†æ¨¡å‹è®¾ç½®ä¸º self.model.eval()
            avg_epoch_test_loss, avg_epoch_test_acc = self.evaluate(self.test_loader, f"æµ‹è¯• (Epoch {epoch + 1})")
            self.test_losses.append(avg_epoch_test_loss)  # è®°å½•å½“å‰epochçš„æµ‹è¯•æŸå¤±
            # self.test_accuracies.append(avg_epoch_test_acc) # (å¯é€‰) è®°å½•å½“å‰epochçš„æµ‹è¯•å‡†ç¡®ç‡

            # æ‰“å°å½“å‰epochçš„è®­ç»ƒå’Œæµ‹è¯•æ€§èƒ½æ€»ç»“
            print(f"--- Epoch {epoch + 1}/{self.epochs} æ€»ç»“ ---")
            print(f"å¹³å‡è®­ç»ƒæŸå¤±: {avg_epoch_train_loss:.4f}")  # | (å¯é€‰) è®­ç»ƒå‡†ç¡®ç‡: {avg_epoch_train_acc*100:.2f}%
            print(f"å¹³å‡æµ‹è¯•æŸå¤±: {avg_epoch_test_loss:.4f} | æµ‹è¯•å‡†ç¡®ç‡: {avg_epoch_test_acc * 100:.2f}%")
            print("-" * 30)  # åˆ†éš”ç¬¦

        training_duration = time.time() - start_time  # è®¡ç®—æ€»è®­ç»ƒæ—¶é•¿
        print(f"è®­ç»ƒå®Œæˆï¼Œæ€»è€—æ—¶: {training_duration:.1f} ç§’ ({training_duration / 60:.2f} åˆ†é’Ÿ)")
        self.save_model()  # è®­ç»ƒå®Œæˆåä¿å­˜æ¨¡å‹

    def plot_losses(self):
        """ç»˜åˆ¶æ¯ä¸ªepochçš„è®­ç»ƒæŸå¤±å’Œæµ‹è¯•æŸå¤±æ›²çº¿å›¾ã€‚"""
        plt.figure(figsize=(12, 6))  # è®¾ç½®å›¾åƒå¤§å°ï¼Œä½¿å…¶æ›´æ˜“è¯»

        # ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
        if self.train_losses:
            plt.plot(self.train_losses, label="Train Loss per Epoch", marker='o', linestyle='-')
        # ç»˜åˆ¶æµ‹è¯•æŸå¤±æ›²çº¿
        if self.test_losses:
            plt.plot(self.test_losses, label="Test Loss per Epoch", marker='x', linestyle='--')

        # è®¾ç½®Xè½´åˆ»åº¦æ ‡ç­¾ä¸ºEpochç¼–å· (1, 2, ..., N)
        if self.epochs > 0:
            tick_labels = [str(i + 1) for i in range(self.epochs)]  # ç”ŸæˆEpochæ ‡ç­¾åˆ—è¡¨
            # å¦‚æœEpochæ•°é‡ä¸å¤š (ä¾‹å¦‚<=20)ï¼Œåˆ™æ˜¾ç¤ºæ‰€æœ‰Epochåˆ»åº¦
            if self.epochs <= 20:
                plt.xticks(range(self.epochs), tick_labels)
            else:  # å¦‚æœEpochæ•°é‡è¾ƒå¤šï¼Œåˆ™æ¯éš”ä¸€å®šæ­¥é•¿æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦ï¼Œé¿å…æ‹¥æŒ¤
                step = max(1, self.epochs // 10)  # è®¡ç®—æ­¥é•¿ï¼Œç¡®ä¿è‡³å°‘ä¸º1ï¼Œå¤§çº¦æ˜¾ç¤º10ä¸ªåˆ»åº¦
                plt.xticks(range(0, self.epochs, step), [tick_labels[i] for i in range(0, self.epochs, step)])

        plt.xlabel("Epoch")  # Xè½´æ ‡ç­¾
        plt.ylabel("Loss")  # Yè½´æ ‡ç­¾
        plt.title("Train vs Test Loss per Epoch")  # å›¾åƒæ ‡é¢˜
        plt.grid(True)  # æ·»åŠ ç½‘æ ¼çº¿ï¼Œæ–¹ä¾¿æŸ¥çœ‹æ•°å€¼

        # è·å–å›¾ä¾‹å¥æŸ„å’Œæ ‡ç­¾ï¼Œä»…åœ¨æœ‰å¯ç»˜åˆ¶çš„çº¿æ¡æ—¶æ˜¾ç¤ºå›¾ä¾‹
        handles, labels = plt.gca().get_legend_handles_labels()
        if handles:
            plt.legend()  # æ˜¾ç¤ºå›¾ä¾‹

        plot_filename = "epoch_loss_curves.png"  # å®šä¹‰ä¿å­˜å›¾åƒçš„æ–‡ä»¶å
        try:
            plt.savefig(plot_filename)  # ä¿å­˜å›¾åƒ
            print(f"ğŸ“ˆ æŸå¤±æ›²çº¿å›¾å·²ä¿å­˜è‡³ {plot_filename}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æŸå¤±æ›²çº¿å›¾å¤±è´¥: {e}")
        finally:
            plt.close('all')  # å…³é—­æ‰€æœ‰matplotlibå›¾åƒçª—å£ï¼Œé‡Šæ”¾èµ„æº

    def run(self):
        """æ‰§è¡Œè®­ç»ƒå™¨çš„ä¸»æµç¨‹ï¼šåŠ è½½æ•°æ®ã€è®­ç»ƒ (æˆ–è·³è¿‡)ã€è¯„ä¼°ã€ç»˜å›¾ã€‚"""
        self.load_data()  # é¦–å…ˆåŠ è½½æ•°æ®

        # æ ¹æ® self.skip_train å†³å®šæ˜¯å¦è·³è¿‡è®­ç»ƒ
        if self.skip_train:
            loaded_successfully = self.load_model()  # å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
            if loaded_successfully:
                print("å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè·³è¿‡è®­ç»ƒï¼Œç›´æ¥è¿›è¡Œæœ€ç»ˆè¯„ä¼°ã€‚")
                # å¦‚æœæ¨¡å‹åŠ è½½æˆåŠŸï¼Œç›´æ¥åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œä¸€æ¬¡æœ€ç»ˆè¯„ä¼°
                self.evaluate(self.test_loader, "æœ€ç»ˆæµ‹è¯•è¯„ä¼° (åŠ è½½æ¨¡å‹å)")
                return  # ç»“æŸrunæ–¹æ³•
            else:
                # å¦‚æœskip_trainä¸ºTrueä½†æ¨¡å‹åŠ è½½å¤±è´¥ (ä¾‹å¦‚æ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸå)
                print("è­¦å‘Šï¼šè®¾ç½®äº†skip_train=Trueï¼Œä½†æ— æ³•åŠ è½½æ¨¡å‹æˆ–æ¨¡å‹ä¸å­˜åœ¨ã€‚å°†å¼€å§‹æ–°çš„è®­ç»ƒã€‚")

        # å¦‚æœä¸è·³è¿‡è®­ç»ƒï¼Œæˆ–è€…è·³è¿‡è®­ç»ƒä½†æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåˆ™æ‰§è¡Œè®­ç»ƒæµç¨‹
        self.train()

        # è®­ç»ƒå®Œæˆåï¼Œåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆçš„è¯„ä¼°å¹¶æ‰“å°ç»“æœ
        print("\n--- è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆè¯„ä¼° ---")
        self.evaluate(self.train_loader, "æœ€ç»ˆè®­ç»ƒé›†è¯„ä¼°")
        self.evaluate(self.test_loader, "æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°")

        # å¦‚æœæ‰§è¡Œäº†è®­ç»ƒ (å³train_lossesåˆ—è¡¨ä¸ä¸ºç©º)ï¼Œåˆ™ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿å›¾
        if self.train_losses and self.test_losses:
            self.plot_losses()
        else:
            # å¦‚æœæ²¡æœ‰è®­ç»ƒæ•°æ® (ä¾‹å¦‚ï¼Œç›´æ¥åŠ è½½æ¨¡å‹å¹¶è¯„ä¼°ï¼Œæˆ–è€…epochsä¸º0)
            print("â„¹ï¸ æœªæ‰§è¡Œè®­ç»ƒæˆ–æŸå¤±æ•°æ®ä¸è¶³ï¼Œä¸ç”ŸæˆæŸå¤±æ›²çº¿å›¾ã€‚")