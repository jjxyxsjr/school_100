import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import os
import time
import copy
import torch.nn.functional as F
from PIL import Image


# ==============================================================================
#  å‡½æ•°å®šä¹‰éƒ¨åˆ† (è¿™éƒ¨åˆ†å®Œå…¨ä¸å˜)
# ==============================================================================
def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=10, device='cpu'):
    since = time.time()
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch + 1}/{num_epochs}')
        print('-' * 10)
        for phase in ['train', 'validation']:
            if phase == 'train':
                model.train()
            else:
                model.eval()
            running_loss = 0.0
            running_corrects = 0
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]
            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')
            if phase == 'train':
                history['train_loss'].append(epoch_loss)
                history['train_acc'].append(epoch_acc.item())
            else:
                history['val_loss'].append(epoch_loss)
                history['val_acc'].append(epoch_acc.item())
            if phase == 'validation' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
        print()
    time_elapsed = time.time() - since
    print(f'è®­ç»ƒå®Œæˆï¼Œè€—æ—¶ {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:4f}')
    model.load_state_dict(best_model_wts)
    return model, history


def plot_curves(history):
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history['train_acc'], label='Train Accuracy')
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend()
    plt.tight_layout()
    plt.show()


def test_model_with_tta(model, test_loader, tta_transforms, device='cpu'):
    print("\nå¼€å§‹ä½¿ç”¨ TTA åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...")
    model.eval()
    total_corrects = 0
    total_images = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            image = inputs[0]
            label = labels[0].to(device)
            augmented_images = torch.stack([tf(image) for tf in tta_transforms]).to(device)
            outputs = model(augmented_images)
            mean_outputs = torch.mean(outputs, dim=0)
            _, pred = torch.max(mean_outputs, 0)
            if pred == label:
                total_corrects += 1
            total_images += 1
    tta_acc = total_corrects / total_images
    print(f'ä½¿ç”¨ TTA çš„æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {tta_acc:.4f} ğŸ¯ğŸš€')


def tta_collate_fn(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    labels = torch.tensor(labels)
    return images, labels


# ==============================================================================
#  ä¸»ç¨‹åºæ‰§è¡Œå—
# ==============================================================================
if __name__ == '__main__':
    # 1. è®¾ç½®è¶…å‚æ•°å’Œè®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨çš„è®¾å¤‡æ˜¯: {device} âœ¨")
    data_dir = 'flower_photos'
    batch_size = 32
    num_epochs = 10
    learning_rate = 0.001

    # 2. æ•°æ®é¢„å¤„ç†ä¸åŠ è½½ (è¿™éƒ¨åˆ†å®Œå…¨ä¸å˜)
    train_val_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'validation': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    tta_transforms = [
        transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    ]

    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), train_val_transforms[x])
                      for x in ['train', 'validation']}
    test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=None)
    image_datasets['test'] = test_dataset
    dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)
                   for x in ['train', 'validation']}
    test_loader_for_tta = DataLoader(image_datasets['test'], batch_size=1, shuffle=False, num_workers=4,
                                     collate_fn=tta_collate_fn)

    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation', 'test']}
    class_names = image_datasets['train'].classes
    num_classes = len(class_names)
    print("æ•°æ®åŠ è½½å®Œæˆï¼")
    print(
        f"è®­ç»ƒé›†å¤§å°: {dataset_sizes['train']}, éªŒè¯é›†å¤§å°: {dataset_sizes['validation']}, æµ‹è¯•é›†å¤§å°: {dataset_sizes['test']}")
    print(f"ç±»åˆ«æ•°é‡: {num_classes}, ç±»åˆ«åç§°: {class_names}")

    # 3. !!! æ„å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ (ä½¿ç”¨EfficientNet) !!!
    print("\næ­£åœ¨æ„å»º EfficientNet-B0 æ¨¡å‹...")
    # åŠ è½½é¢„è®­ç»ƒçš„ EfficientNet-B0
    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)

    # å†»ç»“æ‰€æœ‰ç‰¹å¾æå–å±‚çš„å‚æ•°
    for param in model.parameters():
        param.requires_grad = False

    # è·å–åˆ†ç±»å™¨çš„è¾“å…¥ç‰¹å¾æ•°
    # EfficientNetçš„åˆ†ç±»å™¨æ˜¯ä¸€ä¸ªSequential, æˆ‘ä»¬è¦æ›¿æ¢å…¶ä¸­çš„Linearå±‚(åœ¨ç´¢å¼•1çš„ä½ç½®)
    num_ftrs = model.classifier[1].in_features

    # æ›¿æ¢ä¸ºæˆ‘ä»¬è‡ªå·±çš„åˆ†ç±»å¤´
    model.classifier[1] = nn.Linear(num_ftrs, num_classes)

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
    model = model.to(device)

    # å®šä¹‰æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()

    # å®šä¹‰ä¼˜åŒ–å™¨: åªä¼˜åŒ–æˆ‘ä»¬åˆšåˆšæ›¿æ¢çš„ã€æœªå†»ç»“çš„åˆ†ç±»å¤´çš„å‚æ•°
    # ä¸ºäº†ç¡®ä¿åªè®­ç»ƒåˆ†ç±»å™¨ï¼Œå¯ä»¥æ˜ç¡®åœ°ä¼ é€’å®ƒçš„å‚æ•°
    optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)

    print("æ¨¡å‹æ„å»ºå®Œæˆ!")

    # 4. è®­ç»ƒå’Œç»˜å›¾
    trained_model, history = train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs, device)
    print("\næ­£åœ¨ç»˜åˆ¶è®­ç»ƒæ›²çº¿å›¾...")
    plot_curves(history)

    # 5. è°ƒç”¨TTAæµ‹è¯•å‡½æ•°
    test_model_with_tta(trained_model, test_loader_for_tta, tta_transforms, device)